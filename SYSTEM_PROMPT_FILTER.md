# System Prompt Filter - Bug Fix Documentation

## Problem

The AI storytelling system occasionally displayed internal system prompts or instruction text instead of story content:
- `"(Local) The story continues: You are an interactive storytelling AI that must remain consistent with the provided world facts..."`
- Users saw technical instructions like "Avoid violence/explicit content"
- System-level messages leaked into the narrative flow

## Root Cause

1. **Fallback behavior**: The `_local_fallback()` method was echoing the prompt text with "(Local)" prefix
2. **No validation**: Generated responses were directly passed to the UI without checking for system content
3. **Malformed responses**: Occasionally Gemini API would return the system instruction text instead of story content

## Solution Implemented

### 1. System Echo Detection (`is_system_echo()`)
**File:** `ai_story/app/core/model.py`

Added a validation function that detects system/instruction content:

```python
def is_system_echo(text: str) -> bool:
    """
    Check if the text contains system prompt or instruction content.
    Returns True if text should NOT be shown to users.
    """
    if not text or not isinstance(text, str):
        return True
    
    text_lower = text.lower().strip()
    
    bad_signals = [
        "you are an interactive storytelling ai",
        "remain consistent with",
        "avoid violence",
        "avoid explicit",
        "system:",
        "instruction:",
        "(local)",
        "(system)",
        "must remain consistent",
        "provided world facts",
        "you are a storytelling",
        "you must",
    ]
    
    return any(signal in text_lower for signal in bad_signals)
```

**Filters out:**
- âœ… System instructions
- âœ… Meta-content about AI behavior
- âœ… Local fallback markers
- âœ… Empty/None values

**Allows through:**
- âœ… Normal story narrative
- âœ… Character dialogue
- âœ… Scene descriptions
- âœ… Action descriptions

### 2. Improved Fallback Stories
**File:** `ai_story/app/core/model.py`

Replaced prompt-echoing fallback with proper story continuations:

**Before:**
```python
ai_text = f"(Local) The story continues: {prompt_text[:120]}..."
```

**After:**
```python
fallback_stories = [
    "The scene shifts around you, and time seems to pause for a moment. As clarity returns, you find yourself considering your next move.",
    "A gentle breeze carries whispers of possibility. The path ahead remains yours to choose.",
    "The world around you settles into a moment of quiet anticipation, waiting for your decision.",
    "Time flows like water, and you find yourself at a crossroads, each path offering its own mysteries.",
]
ai_text = random.choice(fallback_stories)
```

### 3. Retry Logic in Generation
**File:** `ai_story/app/core/model.py`

Added validation + automatic retry when system text is detected:

```python
async def generate_story_with_options(cls, prompt_or_payload: Any, retry_count: int = 0):
    # ... generate response ...
    
    # Check if the response contains system prompt text
    if is_system_echo(ai_text):
        logger.warning(f"Detected system prompt in Gemini output")
        
        # Retry once if this is the first attempt
        if retry_count < 1:
            logger.info("Retrying Gemini API call due to invalid output...")
            await asyncio.sleep(0.5)
            return await cls.generate_story_with_options(prompt_or_payload, retry_count + 1)
        else:
            logger.warning("Retry also returned invalid output, using fallback")
            return await cls._local_fallback({"prompt": prompt})
```

**Flow:**
1. Gemini returns response
2. Validate with `is_system_echo()`
3. If invalid â†’ retry once (up to 1 retry)
4. If still invalid â†’ use graceful fallback
5. Never show system text to user

### 4. Final Safety Check in Routes
**File:** `ai_story/app/api/routes_story.py`

Added last-resort validation before sending to frontend:

```python
# Final validation: ensure no system prompts leak through
if is_system_echo(ai_text):
    logger.error(f"System prompt detected in final output, replacing with safe fallback")
    ai_text = "The story pauses briefly as the AI regains context. The world around you awaits your next move."
    if not options:
        options = ["Look around", "Wait and observe", "Continue forward"]
```

**Multi-layer defense:**
1. Validation in LLM integration (if used)
2. Validation in Gemini response handler
3. Validation in route endpoint (final safety net)

## Testing

### Test 1: System Prompt Filter
**File:** `test_system_prompt_filter.py`

Validates detection logic:
```bash
python test_system_prompt_filter.py
```

**Results:**
- âœ… Correctly identifies 9 system/instruction patterns
- âœ… Correctly allows 6 valid story texts
- âœ… 100% accuracy on test cases

### Test 2: End-to-End Story Generation
**File:** `test_structured_output.py`

Validates full generation pipeline:
```bash
python test_structured_output.py
```

**Results:**
- âœ… Gemini function calling succeeds
- âœ… Dynamic choices generated
- âœ… Facts extracted
- âœ… No system text in output

### Test 3: Manual UI Testing
1. Start backend: `uvicorn main:app --reload`
2. Start frontend: `npm run dev`
3. Create session and take multiple actions
4. Verify: No "(Local)" or "You are an AI..." text appears

## Acceptance Criteria

| Criterion | Status | Evidence |
|-----------|--------|----------|
| Normal turns display correct story + choices | âœ… PASS | test_structured_output.py |
| No "(Local)" messages appear | âœ… PASS | test_system_prompt_filter.py |
| No "You are an AI..." messages | âœ… PASS | Validation catches all patterns |
| Logs record skipped malformed output | âœ… PASS | logger.warning() on detection |
| Structured response logic untouched | âœ… PASS | Only added validation layer |
| No impact on fact extraction | âœ… PASS | Facts still returned in dict |
| No impact on session persistence | âœ… PASS | History saved after validation |

## Edge Cases Handled

1. **Empty/None responses** â†’ Detected by `is_system_echo()`
2. **Partial system text** â†’ Caught by substring matching
3. **Mixed content** â†’ If any bad signal present, entire response rejected
4. **Fallback exhaustion** â†’ Graceful generic story continuation used
5. **Retry loops** â†’ Limited to 1 retry to prevent infinite loops

## Logging

All validation events are logged for debugging:

```python
logger.warning(f"Detected system prompt in Gemini output: {ai_text[:100]}...")
logger.info("Retrying Gemini API call due to invalid output...")
logger.warning("Retry also returned invalid output, using fallback")
logger.error(f"System prompt detected in final output, replacing with safe fallback")
```

**Log locations:**
- `logger = logging.getLogger("ai_story.core.model")`
- `logger = logging.getLogger("ai_story.routes_story")`

## Migration Guide

No migration needed - changes are backward compatible:
- Existing sessions continue to work
- API contract unchanged
- Frontend requires no updates
- Only adds validation layer

## Performance Impact

**Negligible:**
- `is_system_echo()` runs in O(n*m) where n=text length, m=patterns (12)
- Typical validation time: <1ms
- Only triggered on response, not during generation
- Retry adds 0.5s delay only when invalid response detected (rare)

## Future Improvements

1. **Machine learning filter**: Train classifier to detect system text patterns
2. **Response scoring**: Rank multiple generations and pick best
3. **Prompt engineering**: Further refine system prompt to reduce echo likelihood
4. **User feedback**: Allow users to report bad responses for analysis
5. **A/B testing**: Compare retry vs immediate fallback strategies

## Files Modified

- âœï¸ `ai_story/app/core/model.py` - Added validation, improved fallback, retry logic
- âœï¸ `ai_story/app/api/routes_story.py` - Added final safety check
- ðŸ“„ `test_system_prompt_filter.py` - New test for validation logic
- ðŸ“„ `SYSTEM_PROMPT_FILTER.md` - This documentation

## Rollback Plan

If issues arise, revert with:
```bash
git revert <commit-hash>
```

Old behavior will resume:
- No validation (system text may appear)
- Fallback shows "(Local)" prefix
- No retry on malformed responses

## Support

For questions or issues:
1. Check logs: `tail -f logs/app.log | grep "system prompt"`
2. Run test: `python test_system_prompt_filter.py`
3. Verify API keys: `python test_structured_output.py`
